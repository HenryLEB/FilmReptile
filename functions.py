# coding=utf-8
import wordcloud
import collections
import re
import numpy as np
import time
from PIL import Image
import jieba
import random
import csv
from bs4 import BeautifulSoup
import pandas as pd
import requests
from pylab import *
from matplotlib.font_manager import FontProperties
from reviewsClass import Review

matplotlib.rc('font', family='SimHei', weight='bold')
plt.rcParams['axes.unicode_minus'] = False

font = FontProperties(fname="C:\Windows\Fonts\simfang.ttf", size=18)


# çˆ¬è™«è¿”å›HTML
def getHtml(url, params=''):
    headers = {
        'User-Agent': 'Mozilla/5.0 (Windows NT 6.1; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/53.0.2785.143 Safari/537.36',
        'Cookie': 'll="118286"; bid=Mt7tz8rljAs; __gads=ID=8a34ed5e7e5b3af7:T=1598885853:S=ALNI_MYjxx1OJjkFbQDKB2k3dZEOaaXrPw; _vwo_uuid_v2=DA22426902ACD9EB4A554A151DF734C59|6b6da08db5b7eec2d60b9c06bce4ed54; push_doumail_num=0; push_noty_num=0; __utmc=30149280; ap_v=0,6.0; dbcl2="215158090:9pSnz0Bd2dg"; ck=HFZN; __utma=30149280.233430570.1598885854.1598954228.1598965289.8; __utmz=30149280.1598965289.8.5.utmcsr=accounts.douban.com|utmccn=(referral)|utmcmd=referral|utmcct=/passport/login; __utmt=1; __utmv=30149280.21515; __utmb=30149280.2.10.1598965289'
    }

    try:
        r = requests.get(url, headers=headers, params=params, timeout=30)
        r.raise_for_status()
        # print(r.status_code)asd
        r.encoding = 'utf-8'
        # r.encoding = r.apparent_encoding
        # print(r.encoding)
        return r.text
    except:
        return ""


# è·å–ç”µå½±è¯¦æƒ…é¡µ
def getFirmDetailsUrl(firm_name):
    douban_url = "https://www.douban.com/search"

    params = {'q': firm_name}
    html = getHtml(douban_url, params)
    soup = BeautifulSoup(html, "html.parser")

    # æ‰¾åˆ°ç”µå½±è¯¦æƒ…é“¾æ¥
    div = soup.find('div', class_='content')

    return div.find('a').attrs['href']


# è·å–å½±è¯„é¡µé¢url
def getFilmReviewUrl(firm_details_url):
    # æ­£åˆ™è¡¨è¾¾å¼ åŒ¹é…ç”µå½±å‚æ•°
    para = re.findall(r'%2F(\d*)%2F', firm_details_url)[1]

    # æ‹¼æ¥ å¾—åˆ°æ‰€æœ‰å½±è¯„é¡µé¢url
    firmReviewUrl = 'https://movie.douban.com/subject/' + para + '/reviews'
    return firmReviewUrl


# è·å–å½±è¯„æœ€å¤§é¡µæ•°çš„å‚æ•° æ¯é¡µç›¸éš”20
def getMAXPages(a_lists):
    max = 0
    for a in a_lists:
        # print(a)
        try:
            if int(a.string) > max:
                max = int(a.string)
        except:
            pass
    else:
        return (max - 1) * 20


# çˆ¬å–æ‰€æœ‰å½±è¯„
def getAllReviews(filmReviewUrl):
    html = getHtml(filmReviewUrl)
    soup = BeautifulSoup(html, "html.parser")
    a_lists = soup.select('.paginator')[0].findAll('a')
    maxPages_para = getMAXPages(a_lists)

    # å…¶å®å‚æ•°ä¸º 0 ----> æœ€å¤§å‚æ•° maxPages_para
    para_page = 0
    # å¼€å§‹å¾ªç¯çˆ¬å–å½±è¯„æ‰€æœ‰é¡µé¢
    all_reviews = []  # æ‰€æœ‰å½±è¯„ï¼ˆä¸åŒ…å«å‰§é€å½±è¯„ï¼‰
    while para_page <= maxPages_para:
        # time.sleep(3)
        url_reviews = filmReviewUrl + '?start=' + str(para_page)
        html_reviews = getHtml(url_reviews)
        soup_reviews = BeautifulSoup(html_reviews, "html.parser")
        div_review_list = soup_reviews.select('.review-list div[data-cid]')

        for item in div_review_list:
            # æ²¡æœ‰è·å–åˆ°çš„æ˜¯ï¼šå‰§é€å½±è¯„
            short_content = item.select('.main-bd .short-content')[0].contents[0].replace('(', '').strip()
            # è·³è¿‡å‰§é€å½±è¯„
            if short_content == '':
                continue

            # è·å–è¯„è®ºç”¨æˆ·çš„ æ˜µç§° è¯„çº§ æ—¶é—´ å…·ä½“è¯„è®ºé“¾æ¥ çŸ­è¯„è®º æœ‰ç”¨æ•°é‡ï¼ˆğŸ‘ï¼‰ æ— ç”¨æ•°é‡ï¼ˆğŸ‘ï¼‰ å›åº”æ•°é‡
            name = item.select('.main-hd a[class=name]')[0].text
            tag_rating = item.find('span', {"class": "main-title-rating"})
            rating = tag_rating['title'] if tag_rating != None else ''
            time = item.find('span', {'class': 'main-meta'}).text
            url_details = item.select('.main-bd h2 a')[0]['href']
            useful_num = item.select('.main-bd .action a[title=æœ‰ç”¨] span')[0].text.strip()
            useless_num = item.select('.main-bd .action a[title=æ²¡ç”¨] span')[0].text.strip()
            reply_num = int(re.findall(r'(\d*)', item.select('.main-bd .action a[class=reply]')[0].text.strip())[0])

            all_reviews.append(
                Review(name, rating, time, url_details, short_content, useful_num, useless_num, reply_num))

        para_page += 20

    else:
        return all_reviews


# å°†çˆ¬å–åˆ°çš„è¯„è®ºæ•°æ® å­˜ä¸ºCSVæ–‡ä»¶
def saveDataToCSV(all_reviews):
    with open('è¯„è®º.csv', 'w', newline='', encoding='utf-8') as f:
        csv_writer = csv.writer(f)
        csv_writer.writerow(['ç”¨æˆ·æ˜µç§°', 'è¯„çº§', 'è¯„è®ºæ—¶é—´', 'è¯„è®ºå†…å®¹ï¼ˆçŸ­è¯„ï¼‰', 'å…·ä½“è¯„è®ºé“¾æ¥', 'ç‚¹èµæ•°', 'ç‚¹è¸©æ•°', 'å›å¤æ•°'])
        for review in all_reviews:
            csv_writer.writerow([review.name, review.rating, review.time, review.short_content,
                                 review.url_details, review.useful_num, review.useless_num, review.reply_num])


# é€šè¿‡ä¼ å…¥çš„csvæ–‡ä»¶ï¼Œå°†æ‰€æœ‰ç”¨æˆ·çš„è¯„è®ºæ‹¼æˆä¸€ä¸ªé•¿çš„å­—ç¬¦ä¸²ï¼Œç”¨äºç”Ÿäº§è¯äº‘
def getStrReview(csvFile):
    data_reviews = pd.DataFrame(csvFile)
    str_reviews = ''
    for review in data_reviews['è¯„è®ºå†…å®¹ï¼ˆçŸ­è¯„ï¼‰']:
        str_reviews += review

    # å»é™¤æ‰€æœ‰æ ‡ç‚¹ç¬¦å·
    str_reviews = re.findall('[\u4e00-\u9fa5]', str_reviews)
    str_reviews = ''.join(str_reviews)

    return str_reviews


# ç»˜åˆ¶è¯„è®ºè¯äº‘å›¾
def drawReviewsCloud(str_reviews):
    words = jieba.lcut(str_reviews)
    counts = {}
    for word in words:  # ç­›é€‰åˆ†æåçš„åè¯
        if len(word) == 1:  # è¯ç»„ä¸­çš„æ±‰å­—æ•°å¤§äº1ä¸ªå³è®¤ä¸ºæ˜¯ä¸€ä¸ªè¯ç»„
            continue
        counts[word] = counts.get(word, 0) + 1

    mask = np.array(Image.open("aixin.png"))
    wcd = wordcloud.WordCloud(
        background_color="white",
        font_path='C:\Windows\Fonts\simfang.ttf',
        max_words=100,
        mask=mask
    )
    wcd.fit_words(counts)
    wcd.to_file("è¯äº‘å›¾-è¯„è®º.png")


def drawSatisfactionAnalysisDiagram(csvFile):
    data_reviews = pd.DataFrame(csvFile)
    satisfaction = data_reviews['è¯„çº§'].value_counts()
    # è¯„çº§æ€»æ•°é‡
    total_ratingNum = int(satisfaction.sum())
    # è¯„çº§æ‰€å æ¯”ä¾‹ï¼š ä¾‹ {'åŠ›è': 0.85 , 'æ¨è': 0.05}
    dict_proportion_rating = {}
    satisfaction = dict(satisfaction)
    for item in satisfaction:
        dict_proportion_rating[item] = round(float(satisfaction[item]) / total_ratingNum, 4)

    # explode = [0.1, 0, 0, 0, 0]
    # explode = explode[0:len(dict_proportion_rating)]
    # è®¾ç½®é¥¼å›¾å‚æ•°
    plt.figure(figsize=(9, 9))
    plt.xticks(fontsize=20)
    plt.yticks(fontsize=20)
    plt.axes(aspect=1)
    colors = ['red', 'pink', 'lightskyblue', 'hotpink', 'yellow']

    patches, l_text, p_text = plt.pie(x=dict_proportion_rating.values(),
                                      labels=dict_proportion_rating.keys(),
                                      autopct='%3.2f%%',
                                      shadow=False,
                                      labeldistance=1.1,
                                      colors=colors,
                                      startangle=90,
                                      pctdistance=0.6, )

    for t in l_text:
        t.set_size(20)
    for t in p_text[0:3]:
        t.set_size(20)
    plt.axis('equal')
    plt.legend()
    plt.savefig('ç”µå½±æ»¡æ„åº¦åˆ†æå›¾.png')
    plt.show()


def drawPeriodOfTimeHistogram(csvFile):
    data_reviews = pd.DataFrame(csvFile)
    dic_time = dict(data_reviews['è¯„è®ºæ—¶é—´'])

    # ä¸€å¤©24å°æ—¶ çˆ¬å–åˆ°çš„ä¸ä¸€å®šåœ¨æ‰€æœ‰çš„æ—¶é—´æ®µ
    time_period = {}
    for i in range(24):
        time_period[str(i).zfill(2)] = 0;

    # é€šè¿‡æ­£åˆ™è¡¨è¾¾å¼ï¼Œä»æ—¥æœŸå­—ç¬¦ä¸²ä¸­æå–å°æ—¶éƒ¨åˆ†
    for item in dic_time:
        dic_time[item] = re.findall(r' (\d*):', dic_time[item])[0]

    dic_time = pd.Series(dic_time).value_counts()
    dic_time = dic_time.sort_index()
    dic_time = dict(dic_time)

    for key in list(dic_time.keys()):
        time_period[key] = dic_time.get(key)

    # è®¾ç½®å‚æ•° ç»˜åˆ¶æ¡å½¢å›¾
    # 24 ä¸ªå°æ—¶
    N = 24

    x = np.arange(N)
    data = list(time_period.values())
    colors = np.random.rand(N * 3).reshape(N, -1)

    labels = []
    for i in range(N):
        labels.append(str(i).zfill(2) + '~' + str(i + 1).zfill(2))

    plt.figure(figsize=(16, 9))
    plt.title("ç½‘å‹è¯„è®ºæ—¶é—´æ®µæ´»è·ƒåº¦åˆ†æ", fontproperties=font)
    plt.xlabel(u"æ—¶é—´æ®µ", fontproperties=font)
    plt.ylabel(u"æ´»è·ƒäººæ•°", fontproperties=font)
    plt.bar(x, data, alpha=0.8, color=colors, tick_label=labels)
    plt.savefig('ç½‘å‹è¯„è®ºæ—¶é—´æ®µæ´»è·ƒåº¦åˆ†æå›¾.png')



    plt.show()
